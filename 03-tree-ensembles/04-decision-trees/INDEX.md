DECISION TREES

Chapter 4 - Breaking Linearity with Axis-Aligned Partitions

Topics:
- Information gain and impurity measures (Gini, Entropy)
- - Splitting criteria and recursion
  - - Overfitting and pruning
    - - Tree depth and complexity
      - - Handling categorical variables
        - - Real-world practical issues
          - - Interview questions
           
            - Why Decision Trees?
            - Trees break away from linear geometry shown in chapters 1-3. They show how to partition space with axis-aligned splits instead of arbitrary hyperplanes, introducing a completely different approach to classification and regression.
           
            - Key Concepts:
            - - Information theory and information gain
              - - Impurity measures
                - - Recursive partitioning
                  - - Greedy splitting strategy
                    - - Bias-variance in trees
